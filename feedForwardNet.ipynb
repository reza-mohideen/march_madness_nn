{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 6\n",
    "hidden_size = 50\n",
    "num_classes = 15\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "TRAIN_DIR = 'D:/PycharmProjects/marchMadness/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data(file):\n",
    "    with open(TRAIN_DIR + '/' + file) as fd:\n",
    "        reader=csv.reader(fd)\n",
    "        data=[row for idx, row in enumerate(reader) if idx in (0,1,2)]\n",
    "        for i in data:\n",
    "            for x in range(0,len(i)):\n",
    "                i[x] = float(i[x])         \n",
    "    return data\n",
    "\n",
    "def labelTM(data):\n",
    "    label = data[2][0]\n",
    "    return label\n",
    "\n",
    "def labelOPP(data):\n",
    "    label = data[2][1]\n",
    "    return label\n",
    "\n",
    "def label_file(file):\n",
    "    word_label = file.split('.')[-6]\n",
    "    if word_label == 'win': \n",
    "        x = 1\n",
    "    elif word_label == 'loss': \n",
    "        x = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    training_labels_tm = []\n",
    "    training_labels_opp = []\n",
    "    for file in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        outcome = label_file(file)\n",
    "        data = read_train_data(file)\n",
    "        scoreTM = int(labelTM(data))\n",
    "        scoreTM = round(scoreTM,-1)\n",
    "        scoreOPP = int(labelOPP(data))\n",
    "        scoreOPP = round(scoreOPP,-1)\n",
    "        training_data.append(torch.FloatTensor(data[:2]).unsqueeze(0))\n",
    "        training_labels_tm.append(scoreTM)\n",
    "        training_labels_opp.append(scoreOPP)\n",
    "        training_labels.append(outcome)\n",
    "    return training_data, training_labels_tm, training_labels_opp, training_labels\n",
    "\n",
    "training_data, training_labels_tm, training_labels_opp, training_labels = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data[:-10000]\n",
    "training_labels = training_labels[:-10000]\n",
    "training_labels_tm = torch.LongTensor(training_labels_tm[:-10000])\n",
    "training_labels_opp = torch.LongTensor(training_labels_opp[:-10000])\n",
    "testing_data = training_data[-10000:]\n",
    "testing_labels_tm = torch.LongTensor(training_labels_tm[-10000:])\n",
    "testing_labels_opp = torch.LongTensor(training_labels_opp[-10000:])\n",
    "testing_labels = torch.LongTensor(training_labels[-10000:])\n",
    "\n",
    "print('No. of training data: ' + str(len(training_data)))\n",
    "print('No. of training labels tm: ' + str(len(training_labels_tm)))\n",
    "print('No. of training labels opp: ' + str(len(training_labels_opp)))\n",
    "print('No. of training labels outcome: ' + str(len(training_labels)))\n",
    "print('No. of testing data: ' + str(len(testing_data)))\n",
    "print('No. of testing labels tm: ' + str(len(testing_labels_tm)))\n",
    "print('No. of testing labels opp: ' + str(len(testing_labels_opp)))\n",
    "print('No. of testing labels outcome: ' + str(len(testing_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, datas, labels1, labels2, labels3):\n",
    "        self.datas = datas\n",
    "        self.labels1 = labels1\n",
    "        self.labels2 = labels2\n",
    "        self.labels3 = labels3\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data, target1, target2, target3 = self.datas[index], self.labels1[index], self.labels2[index], self.labels3[index]\n",
    "        return data, target1, target2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(MyDataset(training_data, training_labels_tm, training_labels_opp, training_labels), batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(MyDataset(testing_data, testing_labels_tm, testing_labels_opp, testing_labels), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc1(x)\n",
    "        x3 = self.fc1(x)\n",
    "        x1 = self.relu(x1)\n",
    "        x2 = self.relu(x2)\n",
    "        x3 = self.relu(x3)\n",
    "        x1 = self.fc2(x1)\n",
    "        x2 = self.fc2(x2)\n",
    "        x3 = self.fc2(x3)\n",
    "        return x1,x2,x3\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(train_dataloader)\n",
    "print(total_step)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, target1, target2, target3) in enumerate(train_dataloader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 2*3).to(device)\n",
    "        target1 = target1.to(device)\n",
    "        target2 = target2.to(device)\n",
    "        target3 = target3.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        out1, out2, out3 = model(images)\n",
    "        #print(out1)\n",
    "        #print('--------------------')\n",
    "        loss1 = criterion(out1, target1)\n",
    "        loss2 = criterion(out2, target2)\n",
    "        loss3 = criterion(out3, target3)\n",
    "        loss = loss1 + loss2 + loss3\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    ".format(epoch+1, num_epochs, i+1, total_step, loss.item()), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, target1, target2 in test_dataloader:\n",
    "        images = images.reshape(-1, 2*3).to(device)\n",
    "        target1 = target1.to(device)\n",
    "        target2 = target2.to(device)\n",
    "        out1, out2 = model(images)\n",
    "        _, predicted1 = torch.max(out1.data, 1)\n",
    "        _, predicted2 = torch.max(out2.data, 1)\n",
    "        print('-----------------------------------------------------------------------------------------------------')\n",
    "        print('score tm: ' + str(target1))\n",
    "        print('score opp: ' + str(target2))\n",
    "        print('predicted tm: ' + str(predicted1))\n",
    "        print('predicted op: ' + str(predicted2))\n",
    "        print('-----------------------------------------------------------------------------------------------------')\n",
    "        total += target1.size(0) + target2.size(0)\n",
    "        correct += (predicted1 == target1).sum().item() + (predicted2 == target2).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
